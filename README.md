# Data-Logistics-Analytics

Proyecto orientado al anÃ¡lisis y procesamiento de datos, utilizando Excel, Python, PostgreSQL y Power BI. Este repositorio documenta el flujo completo desde la normalizaciÃ³n del dataset original hasta su integraciÃ³n en una base de datos relacional para posteriores anÃ¡lisis e informes mediante la creacion de un dashboard.

Este proyecto simula los datos de una empresa logistica (sobre diversos datos de tiempos logÃ­sticos) que cuenta con sucursales en la nacion de colombia teniendo como socio a distribuidoras, los datos fueron sacados del portal de datos abiertos del gobierno colombiano: 

â¡ï¸ **Fuente de Datos:** [Tiempos LogÃ­sticos - datos.gov.co](https://www.datos.gov.co/Transporte/Tiempos-Log-sticos-de-cada-viaje-de-veh-culos-de-c/tfrd-amb4/about_data)

## ğŸ“Œ Objetivos del Proyecto
* Transformar un *dataset* logÃ­stico plano en un conjunto de tablas **normalizadas**.
* Conectar y cargar estas tablas hacia **PostgreSQL** usando Python.
* Preparar la estructura para anÃ¡lisis estratÃ©gicos y *dashboards*.

## ğŸ”§ TecnologÃ­as Utilizadas
| Herramienta | Uso Principal |
| :--- | :--- |
| **Python** (pandas, SQLAlchemy) | ETL, ConexiÃ³n y Carga de datos |
| **PostgreSQL** | Almacenamiento, Modelado Relacional y Consultas |
| **Excel / Power Query** | Limpieza y NormalizaciÃ³n inicial |
| **SQL** | DefiniciÃ³n del esquema y AnÃ¡lisis de negocio |

## ğŸš€ Desarrollo y Componentes del Pipeline

A continuaciÃ³n, se detalla el flujo completo aplicado en este proyecto, desde la normalizaciÃ³n inicial hasta el modelado para Power BI.

### 1ï¸âƒ£ NormalizaciÃ³n de datos (Excel / Power Query)

Componente:
Limpieza, estandarizaciÃ³n y separaciÃ³n lÃ³gica del dataset plano.

Desarrollo:
- Se depuraron columnas inconsistentes.
- Se separaron entidades como transportistas, empresas, viajes, ciudades, etc.
- Se detectaron llaves primarias y llaves forÃ¡neas.
- Se dejÃ³ la estructura lista para migrar a PostgreSQL.

<img src="imagenes/normalizacion.png" alt="Texto alternativo" width="650"/>

---

### 2ï¸âƒ£ MigraciÃ³n y conexiÃ³n Python â†’ PostgreSQL

Componente:
Carga automÃ¡tica de datos a la base de datos relacional.

Desarrollo:

- Se creÃ³ una base de datos nueva en PostgreSQL desde Python usando psycopg2.
- Se leyeron las hojas del archivo Excel normalizado.
- Se crearon tablas base e insertaron registros.

ğŸ“Œ Resultado: Base de datos poblada con las tablas normalizadas.

---

### 3ï¸âƒ£ Modelado relacional en PostgreSQL (SQL)

Componente:
CreaciÃ³n del modelo estrella, claves, relaciones y reglas de integridad.

Desarrollo:

- Se generaron PRIMARY KEY para cada tabla.
- Se crearon FOREIGN KEY segÃºn las relaciones del modelo lÃ³gico.
- Se conectaron las tablas en un esquema tipo estrella.
- Se validaron las relaciones mediante el diagrama ER en la extensiÃ³n de PostgreSQL para VS Code.

<img src="imagenes/esquemaER.png" alt="Texto alternativo" width="350"/>

---

### 4ï¸âƒ£ Columnas Calculadas y AnÃ¡lisis EstratÃ©gico (SQL)

Componente:
**Enriquecimiento del modelo para *Business Intelligence* (BI).**

Desarrollo:
- Se implementÃ³ una columna **`GENERATED ALWAYS AS`** para la **identificaciÃ³n legible** de la empresa de transporte.
- Se desarrollaron **consultas estratÃ©gicas** utilizando **CTEs** y **funciones de agregaciÃ³n** para medir:
    * **Rentabilidad por Hora** (Valor Pagado / Tiempo Total de Ciclo).
    * **Eficiencia GeogrÃ¡fica** y **Tiempos de Manejo** por destino.
    * **ConsolidaciÃ³n de Carga** (anÃ¡lisis de la frecuencia de remesas).

ğŸ“Œ **Resultado:** Modelo robusto y enriquecido, listo para anÃ¡lisis escalables.

---

### 5ï¸âƒ£ IntegraciÃ³n con Power BI (Objetivo Final)

<img src="imagenes/Dashboard.png" alt="Texto alternativo" width="750"/>

Tareas previstas:
- ConexiÃ³n directa a PostgreSQL y validaciÃ³n del esquema.
- CreaciÃ³n de tablas de soporte (e.g., Tabla Calendario).
- Realizar transformaciones, limpiezas previas y columnas calculadas.
- ImplementaciÃ³n de **medidas y KPIs** con DAX.
- ConstrucciÃ³n del *dashboard* analÃ­tico de **tiempos logÃ­sticos**.

ğŸ“Œ Estado: Finalizado.

---

## ğŸ“ Estructura del Repositorio
```
Data-Logistics-Analytics-Pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Dataset limpio y dividido (Excel)
â”‚
â”œâ”€â”€ pythonFiles/
â”‚   â””â”€â”€ Scripts de conexiÃ³n y carga (psycopg2)
â”‚
â”œâ”€â”€ sqlFiles/
â”‚   â””â”€â”€ Consultas SQL, creaciÃ³n de esquema y anÃ¡lisis
â”‚
â”œâ”€â”€ imagenes/
â”‚   â””â”€â”€ ImÃ¡genes de documentaciÃ³n
â”‚
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ Archivo Power BI (.pbix)
â”‚
â””â”€â”€ README.md
    â””â”€â”€ DocumentaciÃ³n principal
```
---

