# Data-Logistics-Analytics

Proyecto orientado al an√°lisis y procesamiento de datos, utilizando Excel, Python, PostgreSQL y Power BI. Este repositorio documenta el flujo completo desde la normalizaci√≥n del dataset original hasta su integraci√≥n en una base de datos relacional para posteriores an√°lisis e informes mediante la creacion de un dashboard.

Este proyecto simula los datos de una empresa logistica (sobre diversos datos de tiempos log√≠sticos) que cuenta con sucursales en la nacion de colombia teniendo como socio a distribuidoras, los datos fueron sacados del portal de datos abiertos del gobierno colombiano: 

‚û°Ô∏è **Fuente de Datos:** [Tiempos Log√≠sticos - datos.gov.co](https://www.datos.gov.co/Transporte/Tiempos-Log-sticos-de-cada-viaje-de-veh-culos-de-c/tfrd-amb4/about_data)

## üìå Objetivos del Proyecto
* Transformar un *dataset* log√≠stico plano en un conjunto de tablas **normalizadas**.
* Conectar y cargar estas tablas hacia **PostgreSQL** usando Python.
* Preparar la estructura para an√°lisis estrat√©gicos y *dashboards*.

## üîß Tecnolog√≠as Utilizadas
| Herramienta | Uso Principal |
| :--- | :--- |
| **Python** (pandas, SQLAlchemy) | ETL, Conexi√≥n y Carga de datos |
| **PostgreSQL** | Almacenamiento, Modelado Relacional y Consultas |
| **Excel / Power Query** | Limpieza y Normalizaci√≥n inicial |
| **SQL** | Definici√≥n del esquema y An√°lisis de negocio |

## üöÄ Desarrollo y Componentes del Pipeline

A continuaci√≥n, se detalla el flujo completo aplicado en este proyecto, desde la normalizaci√≥n inicial hasta el modelado para Power BI.

### 1Ô∏è‚É£ Normalizaci√≥n de datos (Excel / Power Query)

Componente:
Limpieza, estandarizaci√≥n y separaci√≥n l√≥gica del dataset plano.

Desarrollo:
- Se depuraron columnas inconsistentes.
- Se separaron entidades como transportistas, empresas, viajes, ciudades, etc.
- Se detectaron llaves primarias y llaves for√°neas.
- Se dej√≥ la estructura lista para migrar a PostgreSQL.

<img src="imagenes/normalizacion.png" alt="Texto alternativo" width="650"/>

---

### 2Ô∏è‚É£ Migraci√≥n y conexi√≥n Python ‚Üí PostgreSQL

Componente:
Carga autom√°tica de datos a la base de datos relacional.

Desarrollo:

- Se cre√≥ una base de datos nueva en PostgreSQL desde Python usando psycopg2.
- Se leyeron las hojas del archivo Excel normalizado.
- Se crearon tablas base e insertaron registros.

üìå Resultado: Base de datos poblada con las tablas normalizadas.

---

### 3Ô∏è‚É£ Modelado relacional en PostgreSQL (SQL)

Componente:
Creaci√≥n del modelo estrella, claves, relaciones y reglas de integridad.

Desarrollo:

- Se generaron PRIMARY KEY para cada tabla.
- Se crearon FOREIGN KEY seg√∫n las relaciones del modelo l√≥gico.
- Se conectaron las tablas en un esquema tipo estrella.
- Se validaron las relaciones mediante el diagrama ER en la extensi√≥n de PostgreSQL para VS Code.

<img src="imagenes/esquemaER.png" alt="Texto alternativo" width="350"/>

---

### 4Ô∏è‚É£ Columnas Calculadas y An√°lisis Estrat√©gico (SQL)

Componente:
**Enriquecimiento del modelo para *Business Intelligence* (BI).**

Desarrollo:
- Se implement√≥ una columna **`GENERATED ALWAYS AS`** para la **identificaci√≥n legible** de la empresa de transporte.
- Se desarrollaron **consultas estrat√©gicas** utilizando **CTEs** y **funciones de agregaci√≥n** para medir:
    * **Rentabilidad por Hora** (Valor Pagado / Tiempo Total de Ciclo).
    * **Eficiencia Geogr√°fica** y **Tiempos de Manejo** por destino.
    * **Consolidaci√≥n de Carga** (an√°lisis de la frecuencia de remesas).

üìå **Resultado:** Modelo robusto y enriquecido, listo para an√°lisis escalables.

---

### 5Ô∏è‚É£ Integraci√≥n con Power BI (Objetivo Final)

Estado: **En Preparaci√≥n.**

Tareas previstas:
- Conexi√≥n directa a PostgreSQL y validaci√≥n del esquema.
- Creaci√≥n de tablas de soporte (e.g., Tabla Calendario).
- Realizar transformaciones, limpiezas previas y columnas calculadas.
- Implementaci√≥n de **medidas y KPIs** con DAX.
- Construcci√≥n del *dashboard* anal√≠tico de **tiempos log√≠sticos**.

üìå Estado: En preparaci√≥n.

---

## üìÅ Estructura del Repositorio

Data-Logistics-Analytics-Pipeline/
‚îÇ
‚îú‚îÄ‚îÄ data/              # Dataset limpio y dividido (Excel)
‚îú‚îÄ‚îÄ pythonFiles/       # Scripts de conexi√≥n y carga (psycopg2)
‚îú‚îÄ‚îÄ sqlFiles/          # Consultas SQL, creaci√≥n de esquema y an√°lisis
‚îú‚îÄ‚îÄ imagenes/          # Im√°genes de documentaci√≥n
‚îú‚îÄ‚îÄ powerbi/           # (Pendiente) Archivo Power BI (.pbix)
‚îî‚îÄ‚îÄ README.md          # Documentaci√≥n principal
---

